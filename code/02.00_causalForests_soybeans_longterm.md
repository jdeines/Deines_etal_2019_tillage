---
title: "Causal Forest:  Soybeans long-term till status fields"
author: "Jill Deines"
date: "6/14/2019"
output: 
  html_document:
    toc: true
    toc_float: true
    keep_md: true
---

Goal: Implement a causal forest from the `grf` package as a way to compare the effect of high/low till in light of potential confoundedness from field selection bias - if certain fields are low till for a reason.

Goal: Implement a causal forest from the `grf` package as a way to compare the effect of high/low till in light of potential confoundedness from field selection bias - if certain fields are low till for a reason.

Data: field-based long-term data. Here, I sample up to 500 points for each ted (climate soil domains) and tillstatus-year from all available samples (to reduce computational burden and even up samples) and then toss out points with high/low propensities.

Notes: 

* Many causal forest routines take some time to run (up to a few hours), so this script exports intermediate model results as R Data objects (*.rds) for subsequent use/analysis
* due to randomness inherent in random forest routines, rexact esults are unlikely to be reproduced
* SCYM yield values have been adjusted as per Lobell & Azzari 2017, ERL



**R Packages Needed**


```r
library(tidyverse)
library(grf)
library(RColorBrewer)
library(earth)
library(corrplot)
library(car)
library(aod)
library(sf)

library(here)

sessionInfo()
```

```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS  10.14
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] here_0.1           sf_0.7-4           aod_1.3.1         
##  [4] car_3.0-2          carData_3.0-2      corrplot_0.84     
##  [7] earth_4.7.0        plotmo_3.5.2       TeachingDemos_2.10
## [10] plotrix_3.7-4      RColorBrewer_1.1-2 grf_0.10.2        
## [13] forcats_0.3.0      stringr_1.3.1      dplyr_0.8.0.1     
## [16] purrr_0.2.5        readr_1.1.1        tidyr_0.8.1       
## [19] tibble_2.0.1       ggplot2_3.2.0      tidyverse_1.2.1   
## [22] knitr_1.20        
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.0        lubridate_1.7.4   lattice_0.20-35  
##  [4] class_7.3-14      assertthat_0.2.0  rprojroot_1.3-2  
##  [7] digest_0.6.16     R6_2.2.2          cellranger_1.1.0 
## [10] backports_1.1.2   e1071_1.7-0       evaluate_0.11    
## [13] httr_1.3.1        pillar_1.3.1      rlang_0.3.1      
## [16] lazyeval_0.2.1    curl_3.3          readxl_1.1.0     
## [19] rstudioapi_0.7    data.table_1.11.4 Matrix_1.2-14    
## [22] rmarkdown_1.10    foreign_0.8-70    munsell_0.5.0    
## [25] broom_0.5.0       compiler_3.5.1    modelr_0.1.2     
## [28] pkgconfig_2.0.2   htmltools_0.3.6   tidyselect_0.2.5 
## [31] rio_0.5.16        crayon_1.3.4      withr_2.1.2      
## [34] grid_3.5.1        spData_0.2.9.3    DBI_1.0.0        
## [37] nlme_3.1-137      jsonlite_1.6      gtable_0.2.0     
## [40] magrittr_1.5      units_0.6-1       scales_1.0.0     
## [43] zip_2.0.1         cli_1.0.1         stringi_1.2.4    
## [46] xml2_1.2.0        openxlsx_4.1.0    tools_3.5.1      
## [49] glue_1.3.0        hms_0.4.2         abind_1.4-5      
## [52] yaml_2.2.0        colorspace_1.3-2  classInt_0.2-3   
## [55] rvest_0.3.2       haven_1.1.2
```

**Directories**


```r
# input/cleaned data folder
dataFolder <- paste0(here::here(),'/data/tabular_field_data')
dataFileNameAll <-  '/soy_longterm_fields_20190616.rds'
  
# output scratch folder for model output rdata objects
scratchFolder <- paste0(here::here(),'/data/model_output/causalForest_soybean_Longterm')

# make scratch folder if necessary
dir.create(file.path(scratchFolder), showWarnings = FALSE)
```

# Load and Sample Data

## load and clean


```r
# all cleaned data
tillYears <- readRDS(paste0(dataFolder,dataFileNameAll)) 

# combine some variables, remove reduncancies
tillYears2 <- tillYears %>% 
  mutate(awc_lay1_2 = awc_lay1 + awc_lay2,
         sandtotal_lay1_2 = (sandtotal_r_lay1 + sandtotal_r_lay2)/2,
         claytotal_lay1_2 = (claytotal_r_lay1 + claytotal_r_lay2)/2,
         silttotal_lay1_2 = 100 - sandtotal_lay1_2 - claytotal_lay1_2,
         ksat_lay1_2 = (ksat_lay1 + ksat_lay2)/2) %>%
  dplyr::select(-c(contains('_r_'),
                   awc_lay1, awc_lay2, ksat_lay1, ksat_lay2)) 
 
# clean outliers from SCYM
summary(tillYears2$yield_tha)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.00136 2.95244 3.40555 3.25637 3.74675 5.78644
```

```r
cleanQ <- quantile(tillYears2$yield_tha, probs = c(0.0001, 0.9999), na.rm=TRUE)
cleanQ
```

```
##      0.01%     99.99% 
## 0.03139849 5.00264079
```

```r
# remove outliers: 
tillYearsAll <- tillYears2 %>%
  ungroup() %>%
  filter(yield_tha > cleanQ[1]) %>%
  filter(yield_tha < cleanQ[2]) %>%
  tidyr::drop_na() %>%
  mutate(uniqueID = row_number())

length(unique(tillYearsAll$pointID))                       
```

```
## [1] 101452
```

```r
tillYearsAllConstant <- tillYearsAll %>%  filter(tillStatus == 'constant_high') 
length(unique(tillYearsAllConstant$pointID)) 
```

```
## [1] 39581
```

```r
tillYearsAllConstantLow <- tillYearsAll %>%  filter(tillStatus == 'constant_low') 
length(unique(tillYearsAllConstantLow$pointID)) 
```

```
## [1] 61871
```

```r
table(tillYearsAll$tillStatus)
```

```
## 
## constant_high  constant_low 
##        197818        306916
```

## make sample - all
sample more evenly across teds - set maximum samples per ted to reduce dataset set in a more balanced way


```r
# treatment converter key
binary <- data.frame(tillStatus = c('constant_high','constant_low'),
                     W = c(0,1))

tillYearsAll2 <- tillYearsAll %>%
  left_join(binary) %>%
  rename(Y = yield_tha)
```

```
## Joining, by = "tillStatus"
```

```
## Warning: Column `tillStatus` joining character vector and factor, coercing
## into character vector
```

```r
# extract balanced thing for training
samples_per_group <- 500
set.seed(5)
constantLess <- tillYearsAll2 %>%
  group_by(ted, tillStatus, year) %>%
  sample_n(., size = min(samples_per_group, n()), replace = FALSE) %>%
  ungroup() %>%
  mutate(year = as.integer(year),
         previousCorn = as.integer(previousCorn))

table(constantLess$tillStatus)
```

```
## 
## constant_high  constant_low 
##         92037        100222
```

```r
table(constantLess$year)
```

```
## 
##  2005  2006  2007  2008  2009  2010  2011  2012  2013  2014  2015 
## 18543 17685 17476 18120 17330 18294 18023 14033 17443 17825 17487
```

```r
table(constantLess[,c('tillStatus','year')])
```

```
##                year
## tillStatus      2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015
##   constant_high 9103 8484 8374 8406 8419 8573 8711 6386 8576 8561 8444
##   constant_low  9440 9201 9102 9714 8911 9721 9312 7647 8867 9264 9043
```

```r
table(tillYearsAll2$tillStatus)
```

```
## 
## constant_high  constant_low 
##        197818        306916
```

```r
# how many repeat points
nrow(constantLess)
```

```
## [1] 192259
```

```r
sum(duplicated(constantLess$pointID))
```

```
## [1] 118261
```

```r
length(unique(constantLess$pointID))
```

```
## [1] 73998
```

# Causal forests

## Propensity scores
using soil and normals - static variables

The overlap assumption is violated with propensities very near 0 and 1, so remove data when W.hat < 0.05 and W.hat > 0.95


```r
# covariates: climate normals and soil variables
X_norm <- constantLess %>%
  select(c(contains('norm'), contains('lay1'), 'slope'))

# treatment
W <- constantLess %>% dplyr::pull(W)

# run
W_forest <- grf::regression_forest(X_norm, W, num.trees = 2000)
W_hat <- predict(W_forest)$predictions

WvarImp <- W_forest %>% 
  variable_importance() %>% 
  as.data.frame() %>% 
  mutate(variable = colnames(W_forest$X.orig)) %>% 
  arrange(desc(V1))

# check propensity scores
p_rf = W_hat
hist(p_rf)

sum(p_rf == 0)
min(p_rf)
sum(p_rf < .005)

sum(p_rf == 1)
max(p_rf)
sum(p_rf > .995)

{plot(smooth.spline(p_rf, W, df = 4))
abline(0, 1)}

# save intermediates
saveRDS(constantLess, paste0(scratchFolder, '/constantLess.rds'))
saveRDS(W_forest, paste0(scratchFolder, '/W_forest.rds'))
saveRDS(W_hat, paste0(scratchFolder, '/W_hat.rds'))
saveRDS(WvarImp, paste0(scratchFolder, '/W_forest_varImp.rds'))
```

## Prune Samples
Toss out rows with excessively high/low propensities

### Compare Propensity Filters


```r
# re-load so chunk runs in markdown output
constantLess <- readRDS(paste0(scratchFolder, '/constantLess.rds'))
W_hat <- readRDS(paste0(scratchFolder, '/W_hat.rds'))
W <- constantLess %>% dplyr::pull(W)
p_rf = W_hat

# filter it
overlap0 <- constantLess %>%
  mutate(w_hat = W_hat) %>%
  mutate(keep = case_when(w_hat < 0.05 | w_hat > 0.95 ~ 0,
                        w_hat >= 0.05 | w_hat <= 0.95  ~ 1))
overlap <- overlap0 %>% filter(keep == 1)
nrow(overlap0) - nrow(overlap)
```

```
## [1] 72593
```

```r
nrow(overlap)
```

```
## [1] 119666
```

```r
table(overlap$tillStatus)
```

```
## 
## constant_high  constant_low 
##         68428         51238
```

```r
table(overlap$year)
```

```
## 
##  2005  2006  2007  2008  2009  2010  2011  2012  2013  2014  2015 
## 11274 11149 11161 11230 10737 11628 11064  8266 10901 11334 10922
```

```r
table(overlap[,c('tillStatus','year')])
```

```
##                year
## tillStatus      2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015
##   constant_high 6566 6389 6381 6236 6196 6504 6399 4616 6401 6488 6252
##   constant_low  4708 4760 4780 4994 4541 5124 4665 3650 4500 4846 4670
```

```r
# compare remaining teds
unique(constantLess$ted)
```

```
##  [1] 103503 103603 103703 104603 104803 105703 203503 203603 203703 204503
## [11] 204603 204803 205703 303503 303603 303703 304403 304503 304603 304803
## [21] 305703 305803 403403 403503 403603 403703 404403 404503 404603 404803
## [31] 405703 405803 454803 503403 503503 503603 503703 504403 504503 504603
## [41] 504803 505703 505803 603403 603503 603603 603703 604403 604503 604603
## [51] 604803 605703 605803 703403 703503 703603 703703 704403 704503 704603
## [61] 704803 705703 705803
```

```r
unique(overlap$ted)
```

```
##  [1] 103503 103603 103703 104603 104803 105703 203503 203603 203703 204503
## [11] 204603 204803 205703 303503 303603 303703 304503 304603 304803 305703
## [21] 305803 403403 403503 403603 403703 404403 404503 404603 404803 405703
## [31] 405803 503403 503503 503603 503703 504403 504503 504603 504803 505703
## [41] 505803 603403 603503 603603 603703 604503 604603 604803 605703 703403
## [51] 703503 703603 703703 704403 704503 704603 704803 705703
```

```r
both <- data.frame(W_hat = W_hat,
                   type = 'All') %>%
  bind_rows(data.frame(W_hat = overlap$w_hat,
                       type = 'Filtered'))
```

```
## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character
```

```
## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector
```

```r
ggplot(both,
       aes(x = W_hat)) +
  geom_histogram() +
  geom_vline(xintercept = 0.05, col='red') +
  geom_vline(xintercept = 0.95, col = 'red') +
  facet_wrap(~type) +
  theme_bw()
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

![](../figure/02.00_causalSoy/propensityFilter-1.png)<!-- -->

```r
{plot(smooth.spline(p_rf, W, df = 4))
abline(0, 1)}
```

![](../figure/02.00_causalSoy/propensityFilter-2.png)<!-- -->

```r
{plot(smooth.spline(overlap$w_hat, overlap$W, df = 4))
abline(0, 1)}
```

![](../figure/02.00_causalSoy/propensityFilter-3.png)<!-- -->

```r
# save overlap data!
saveRDS(overlap, paste0(scratchFolder, '/overlap.rds'))
```


## expected outcome: Y.hat
i guess do this individually too? on overlapped data

### Pick covars


```r
overlap <- readRDS(paste0(scratchFolder, '/overlap.rds'))

# pick subset of variables by dropping stuff: candidate 1
X_c1 <- overlap %>%
  select(-c(pointID, fips, pxCount, nObs, W, uniqueID,
            contains('norm'), contains('ted')))

# mars for var selection
set.seed(5)
marsAll <- earth::earth(Y ~ ., data = X_c1, degree = 2)
summary(marsAll)
ev <- evimp(marsAll) # estimate variable importance
plot(ev)
ev

saveRDS(marsAll, paste0(scratchFolder, '/mars_c1.rds'))
```

### Train Yhat


```r
# variables from mars
marsAll <- readRDS(paste0(scratchFolder, '/mars_c1.rds'))
summary(marsAll)
ev <- evimp(marsAll) # estimate variable importance
plot(ev)
ev

envvars <- rownames(ev)

varsToKeep = c(envvars, 'srad_jja')


X <- overlap %>%
  select(varsToKeep)

corr <- cor(X )
corrplot(corr, type = 'upper')

# outcome
Y <- overlap %>% dplyr::pull(Y)

Y_forest <- grf::regression_forest(X, Y, num.trees = 2000)

YvarImp <- Y_forest %>% 
  variable_importance() %>% 
  as.data.frame() %>% 
  mutate(variable = colnames(Y_forest$X.orig)) %>% 
  arrange(desc(V1))
YvarImp


Y_hat <- predict(Y_forest)$predictions

Ychecker <- data.frame(Y = Y,
                       Y_hat = Y_hat,
                       year = overlap$year)
Yagreement <- lm(Y~Y_hat)
summary(Yagreement)

ggplot(Ychecker, aes(x=Y, y = Y_hat)) +
  geom_hex() +
  scale_fill_gradientn(colors = brewer.pal(9,'YlGnBu')) +
  geom_smooth(method= 'lm') +
  coord_equal(xlim=c(0,6), ylim=c(0,6)) + 
  geom_abline(slope = 1, intercept = 0, linetype='dashed') + 
  facet_wrap(~year) +
  theme_bw()

saveRDS(Y_hat, paste0(scratchFolder, '/Y_hat.rds'))
saveRDS(Y_forest, paste0(scratchFolder, '/Y_forest.rds'))
saveRDS(YvarImp, paste0(scratchFolder, '/Y_forest_varImp.rds'))
```

## causal forest


```r
# reload overlap
overlap <- readRDS(paste0(scratchFolder, '/overlap.rds'))
Y_hat <- readRDS(paste0(scratchFolder, '/Y_hat.rds'))

# reload mars variables
marsAll <- readRDS(paste0(scratchFolder, '/mars_c1.rds'))
ev <- evimp(marsAll) # estimate variable importance
envvars <- rownames(ev)

# treatment
W <- overlap %>% dplyr::pull(W)
w_hat <- overlap$w_hat

# outcome
Y <- overlap %>% dplyr::pull(Y)

# make covariate list; 
# add in important propensity variables, and things i like (GDD), sherries impt var (tcsoilmapr)
varsToKeep_main = c(envvars,'srad_jja', 'tc_soilm_apr', 
               'silttotal_lay1_2', 'ppt_apr','awc_lay1_2',   'vpd_july',  
               'meanTemp_apr', 'slope', 'tmin_jun')


Xmain <- overlap %>%
  select(varsToKeep_main)

corr <- cor(Xmain )
corrplot(corr, type = 'upper')


cf <- grf::causal_forest(Xmain, Y, W, Y_hat, w_hat, num.trees = 2000)

ate_cf_aipw = average_treatment_effect(cf)
ate_cf_aipw = average_treatment_effect(cf, target.sample = 'overlap')
tauhat_rf_aipw = c(ATE=ate_cf_aipw["estimate"],
                   lower_ci=ate_cf_aipw["estimate"] - 1.96 * ate_cf_aipw["std.err"],
                   upper_ci=ate_cf_aipw["estimate"] + 1.96 * ate_cf_aipw["std.err"])
tauhat_rf_aipw

varImpMain <- cf %>% 
  variable_importance() %>% 
  as.data.frame() %>% 
  mutate(variable = colnames(cf$X.orig)) %>% 
  arrange(desc(V1))


saveRDS(cf, paste0(scratchFolder, '/cf_xc1.rds'))
saveRDS(varImpMain, paste0(scratchFolder, '/cf_xc1_varImp.rds'))
```


# Checking things out

reload rdata stuff


```r
overlap <- readRDS(paste0(scratchFolder, '/overlap.rds'))

# marsAll <- readRDS(paste0(scratchFolder, '/mars_c1.rds'))


#W_forest <- readRDS(paste0(scratchFolder, '/W_forest.rds'))
#W_hat <- readRDS(paste0(scratchFolder, '/W_hat.rds'))
W_hat <- overlap %>% dplyr::pull(w_hat)
WvarImp <- readRDS(paste0(scratchFolder, '/W_forest_varImp.rds'))

#Y_forest <- readRDS(paste0(scratchFolder, '/Y_forest.rds'))
Y_hat <- readRDS(paste0(scratchFolder, '/Y_hat.rds'))
YvarImp <- readRDS(paste0(scratchFolder, '/Y_forest_varImp.rds'))

cf <- readRDS(paste0(scratchFolder, '/cf_xc1.rds'))
varImp <- readRDS(paste0(scratchFolder, '/cf_xc1_varImp.rds'))

# covariates: climate normals and soil variables
X_norm <- overlap %>%
  select(c(contains('norm'), contains('lay1'), 'slope'))

# treatment
W <- overlap %>% dplyr::pull(W)
Y <- overlap %>% dplyr::pull(Y)

constantLess <- readRDS(paste0(scratchFolder, '/constantLess.rds'))
allWhat <- readRDS(paste0(scratchFolder, '/W_hat.rds'))

# add hats to original data frame
overlapW0 <- overlap %>%
  bind_cols(data.frame(Y_hat = Y_hat))

# calculate quantiles of interest
colNormals <- names(X_norm)
colVars <- varImp %>% dplyr::pull(variable)

overlapW <- overlapW0 %>%
  mutate_at(colNormals, list(Q4n = ~ntile(., 4),
                           Q5n = ~ntile(., 5))) %>%
  mutate_at(colVars, list(Q4 = ~ntile(., 4),
                           Q5 = ~ntile(., 5)))
```


## propensities


```r
# check propensity scores
p_rf = W_hat
hist(p_rf)
```

![](../figure/02.00_causalSoy/propensity1-1.png)<!-- -->

```r
sum(p_rf == 0)
```

```
## [1] 0
```

```r
min(p_rf)
```

```
## [1] 0.05000363
```

```r
sum(p_rf < .005)
```

```
## [1] 0
```

```r
sum(p_rf == 1)
```

```
## [1] 0
```

```r
max(p_rf)
```

```
## [1] 0.9499988
```

```r
sum(p_rf > .995)
```

```
## [1] 0
```

```r
{plot(smooth.spline(p_rf, W, df = 4))
abline(0, 1)}
```

![](../figure/02.00_causalSoy/propensity1-2.png)<!-- -->

```r
WvarImp
```

```
##              V1         variable
## 1  0.7083362805            slope
## 2  0.1257932927   pr_may_norm_mm
## 3  0.0877490854  temp_apr_norm_C
## 4  0.0191582317 vpd_jun_norm_hPa
## 5  0.0189365854 silttotal_lay1_2
## 6  0.0128451220   pr_apr_norm_mm
## 7  0.0097740854 claytotal_lay1_2
## 8  0.0029896341   pr_jul_norm_mm
## 9  0.0028661585  temp_aug_norm_C
## 10 0.0028161585   pr_jun_norm_mm
## 11 0.0026429878       awc_lay1_2
## 12 0.0018362805  temp_jul_norm_C
## 13 0.0016106707  temp_may_norm_C
## 14 0.0013268293  temp_jun_norm_C
## 15 0.0009545732 vpd_jul_norm_hPa
## 16 0.0002487805 sandtotal_lay1_2
## 17 0.0001152439      ksat_lay1_2
```

## Outcome estimation Y hat


```r
YvarImp 
```

```
##              V1         variable
## 1  0.6427411585          aridity
## 2  0.0832783537     previousCorn
## 3  0.0695664634       tc_def_jul
## 4  0.0631106707         srad_jja
## 5  0.0431658537          ppt_jun
## 6  0.0327606707           GDD_ss
## 7  0.0150481707     tc_soilm_may
## 8  0.0119231707       tc_def_jun
## 9  0.0103960366          ppt_may
## 10 0.0079454268         pr_early
## 11 0.0064246951          ppt_jul
## 12 0.0053814024     tc_soilm_jul
## 13 0.0040472561 sandtotal_lay1_2
## 14 0.0022582317          ppt_apr
## 15 0.0008314024          pr_grow
## 16 0.0005024390 claytotal_lay1_2
## 17 0.0003564024         tmin_aug
## 18 0.0002621951             year
```

```r
Ychecker <- data.frame(Y = Y,
                       Y_hat = Y_hat,
                       year = overlap$year)
Yagreement <- lm(Y~Y_hat)
summary(Yagreement)
```

```
## 
## Call:
## lm(formula = Y ~ Y_hat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7712 -0.2149  0.0701  0.3066  2.4882 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.337668   0.011581  -29.16   <2e-16 ***
## Y_hat        1.102531   0.003497  315.32   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.5215 on 119664 degrees of freedom
## Multiple R-squared:  0.4538,	Adjusted R-squared:  0.4538 
## F-statistic: 9.943e+04 on 1 and 119664 DF,  p-value: < 2.2e-16
```

```r
# yield year by year
YcheckerLong <- Ychecker %>%
  tidyr::gather(., key = variable, value = value, Y:Y_hat)


ggplot(YcheckerLong, aes(x=as.factor(year), y = value, group = interaction(year,variable), 
                         fill = variable)) +
  geom_boxplot() +
  theme_bw() +
  ylab('Yield (t/ha)') +
  xlab('Year')
```

![](../figure/02.00_causalSoy/yhat_check-1.png)<!-- -->


# average treatment effects

## variable importance


```r
varImp
```

```
##             V1         variable
## 1  0.177223965     tc_soilm_may
## 2  0.168615587     tc_soilm_apr
## 3  0.119797326            slope
## 4  0.116842015     tc_soilm_jul
## 5  0.096474769 silttotal_lay1_2
## 6  0.087490145          ppt_jul
## 7  0.032660840          aridity
## 8  0.020422575 claytotal_lay1_2
## 9  0.019053844 sandtotal_lay1_2
## 10 0.015012896          ppt_jun
## 11 0.014815570         tmin_aug
## 12 0.014759799           GDD_ss
## 13 0.014704785       awc_lay1_2
## 14 0.013897104         vpd_july
## 15 0.011568221         pr_early
## 16 0.009710392         srad_jja
## 17 0.009666443     meanTemp_apr
## 18 0.009562651          ppt_may
## 19 0.009327117          pr_grow
## 20 0.008889965     previousCorn
## 21 0.008245583          ppt_apr
## 22 0.007980726         tmin_jun
## 23 0.005018867             year
## 24 0.004163915       tc_def_jun
## 25 0.004094902       tc_def_jul
```


## oob data


```r
ate_cf_aipw = average_treatment_effect(cf)
ate_cf_aipw = average_treatment_effect(cf)
tauhat_rf_aipw = c(ATE=ate_cf_aipw["estimate"],
                   lower_ci=ate_cf_aipw["estimate"] - 1.96 * ate_cf_aipw["std.err"],
                   upper_ci=ate_cf_aipw["estimate"] + 1.96 * ate_cf_aipw["std.err"])
tauhat_rf_aipw
```

```
##      ATE.estimate lower_ci.estimate upper_ci.estimate 
##        0.02427196        0.01729434        0.03124958
```

## plot raw treatment effects
not doubly robust?


```r
# add predicted treatment effects to data 
constOob_predict <- predict(cf)

overlapTau <- overlapW %>%
  bind_cols(constOob_predict) 


ggplot(overlapTau,
       aes(x = predictions)) +
  geom_histogram() +
  xlim(-1,2)+
  xlab('CATE') +
  geom_vline(xintercept = 0, col = 'black', linetype = 'dashed') +
  geom_vline(xintercept = ate_cf_aipw["estimate"], col = 'red') +
  theme_bw()
```

```
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
```

```
## Warning: Removed 2 rows containing missing values (geom_bar).
```

![](../figure/02.00_causalSoy/cf_predict_oob-1.png)<!-- -->

```r
ggplot(overlapTau,
       aes(x = year, y = predictions, group = year)) +
  geom_boxplot() +
  theme_bw() + ggtitle('oob predicted treatment effects')
```

![](../figure/02.00_causalSoy/cf_predict_oob-2.png)<!-- -->


# HTE 
test for heterogeneous treatment effects from Athey & Wagner preprint 2019


```r
# run best linear predictor analysis
calibration <- test_calibration(cf)
calibration
```

```
## 
## Best linear fit using forest predictions (on held-out data)
## as well as the mean forest prediction as regressors, along
## with heteroskedasticity-robust (HC3) SEs:
## 
##                                Estimate Std. Error t value  Pr(>|t|)    
## mean.forest.prediction         1.036012   0.241600  4.2881 1.803e-05 ***
## differential.forest.prediction 1.350079   0.052292 25.8183 < 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

heterogeneity! see Fig 2 and 3 code for heterogeneity breakdowns

## Variable correlations


```r
causalVars <- overlap %>% dplyr::select(varImp$variable)

corr <- cor(causalVars)
corrplot(corr, type = 'upper')
```

![](../figure/02.00_causalSoy/varCorr-1.png)<!-- -->
